# 캐시 스탬피드 현상
**ID:** 202509215_캐시스탬피드현상
**생성일:** 2025-09-21
**태그:** #캐시 #성능문제 #동시성

## 핵심 개념

캐시 스탬피드(Cache Stampede) 현상은 캐시가 만료되거나 비어있을 때 다수의 요청이 동시에 데이터베이스에 접근하는 현상이다. 이로 인해 DB에 갑작스러운 부하가 집중되어 성능 저하나 장애가 발생할 수 있다.

## 발생 메커니즘

1. 인기 있는 데이터의 캐시가 만료됨
2. 동시에 여러 요청이 해당 데이터를 요청
3. 모든 요청이 캐시 미스를 경험
4. 동시에 여러 요청이 DB에 동일한 쿼리를 실행
5. DB에 순간적으로 높은 부하 발생

## 실제 예시

```
시간 0: 상품 정보 캐시 만료 (TTL 만료)
시간 1: 100명의 사용자가 동시에 같은 상품 페이지 요청
결과: 100개의 동일한 DB 쿼리가 동시 실행
```

## 해결 방안

### 1. 세마포어 잠금 메커니즘

```python
import threading
from threading import Lock

cache_locks = {}

def get_data_with_lock(key):
    if key not in cache_locks:
        cache_locks[key] = Lock()

    with cache_locks[key]:
        # 다시 한 번 캐시 확인 (Double-Checked Locking)
        data = cache.get(key)
        if data is not None:
            return data

        # 첫 번째 요청만 DB에 접근
        data = database.query(key)
        cache.set(key, data, ttl=3600)
        return data
```

### 2. 확률적 조기 만료

- TTL 만료 시간 근처에서 확률적으로 캐시를 미리 갱신
- 모든 요청이 동시에 만료되는 것을 방지

### 3. 백그라운드 갱신

```python
def background_refresh():
    # 만료 예정인 인기 캐시들을 미리 갱신
    for key in popular_keys:
        if cache.ttl(key) < refresh_threshold:
            schedule_refresh(key)
```

## 모니터링 지표

- **동시 DB 쿼리 수**: 같은 쿼리의 동시 실행 횟수
- **DB 응답 시간 스파이크**: 캐시 만료 시점의 DB 성능
- **캐시 미스 패턴**: 동시 캐시 미스 발생 빈도

## 관련 개념

- [[202509213_Look-Aside캐시패턴]] - 스탬피드 현상이 발생하는 기본 패턴
- [[202509216_TTL설정전략]] - 스탬피드 현상을 줄이는 TTL 전략
- [[202509219_캐시워밍전략]] - 미리 캐시를 준비하여 문제 예방

## 결론

캐시 스탬피드는 고트래픽 시스템에서 흔히 발생하는 문제로, 잠금 메커니즘이나 백그라운드 갱신 등의 전략을 통해 예방할 수 있다. 시스템의 특성에 맞는 적절한 해결책을 선택하는 것이 중요하다.