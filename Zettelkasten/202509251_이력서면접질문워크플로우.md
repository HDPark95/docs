# 이력서 기반 면접 질문 생성 워크플로우

## 개요
n8n 기반 자동화 워크플로우로 구현하는 지능형 면접 질문 생성 시스템. Dolphin으로 이력서를 파싱하고, 다중 LLM을 활용해 맞춤형 기술/행동/상황 면접 질문을 자동 생성. 직무별, 경력별, 기술 스택별 최적화된 질문과 예상 답변 가이드 제공.

## 1. 아키텍처 설계

### 1.1 면접 질문 생성 워크플로우

```mermaid
graph TB
    Start([이력서 + JD 업로드]) --> Validate{파일 검증}
    Validate -->|Valid| Process[전처리]
    Validate -->|Invalid| Error[에러 처리]

    Process --> Dolphin[Dolphin 파싱]
    Dolphin --> Extract[정보 추출]

    Extract --> Analysis{분석 단계}

    Analysis --> Career[경력 분석]
    Analysis --> Skills[기술 스택 분석]
    Analysis --> Projects[프로젝트 분석]
    Analysis --> Gaps[공백/전환 분석]

    Career --> QGen{질문 생성 엔진}
    Skills --> QGen
    Projects --> QGen
    Gaps --> QGen

    QGen --> Tech[기술 질문<br/>생성]
    QGen --> Behavioral[행동 질문<br/>생성]
    QGen --> Situational[상황 질문<br/>생성]
    QGen --> Cultural[문화 적합성<br/>질문]

    Tech --> LLM1[Claude<br/>심층 기술 질문]
    Behavioral --> LLM2[GPT-4<br/>STAR 기반 질문]
    Situational --> LLM3[Gemini<br/>시나리오 질문]
    Cultural --> LLM4[LLaMA<br/>가치관 질문]

    LLM1 --> Difficulty{난이도 조정}
    LLM2 --> Difficulty
    LLM3 --> Difficulty
    LLM4 --> Difficulty

    Difficulty --> Junior[주니어 레벨]
    Difficulty --> Mid[미드 레벨]
    Difficulty --> Senior[시니어 레벨]

    Junior --> Format[포맷팅]
    Mid --> Format
    Senior --> Format

    Format --> Output{출력 형태}
    Output --> PDF[PDF 문서]
    Output --> API[API Response]
    Output --> Interactive[대화형 시뮬레이터]
    Output --> DB[(질문 DB 저장)]
```

### 1.2 n8n 워크플로우 노드 구성

#### 트리거 노드
- **Webhook**: 이력서 파일 수신
- **Google Drive Trigger**: 특정 폴더 모니터링
- **Email Trigger**: 이메일 첨부파일 처리
- **Schedule Trigger**: 배치 처리

#### 처리 노드
- **HTTP Request**: Dolphin API 호출
- **Function**: 커스텀 파싱 로직
- **Split in Batches**: 대량 처리
- **Merge**: 병렬 결과 통합

#### 통합 노드
- **OpenAI**: GPT-4 분석
- **Anthropic**: Claude 평가
- **Google Vertex AI**: Gemini 검토
- **PostgreSQL**: 데이터 저장
- **Redis**: 캐싱 처리

## 2. 고도화된 파싱 파이프라인

### 2.1 다단계 전처리 플로우

```mermaid
sequenceDiagram
    participant User
    participant n8n
    participant Preprocessor
    participant Dolphin
    participant Validator
    participant Enricher

    User->>n8n: Upload Resume
    n8n->>Preprocessor: File Validation
    Preprocessor->>Preprocessor: Format Detection
    Preprocessor->>Preprocessor: Quality Check
    Preprocessor->>Preprocessor: Image Enhancement
    Preprocessor->>Dolphin: Processed Image
    Dolphin->>Dolphin: Layout Analysis
    Dolphin->>Dolphin: Element Detection
    Dolphin->>Validator: Raw JSON
    Validator->>Validator: Schema Validation
    Validator->>Validator: Data Consistency
    Validator->>Enricher: Validated JSON
    Enricher->>Enricher: NER Processing
    Enricher->>Enricher: Date Normalization
    Enricher->>Enricher: Skill Extraction
    Enricher->>n8n: Enriched Data
```

### 2.2 향상된 데이터 구조

```json
{
  "metadata": {
    "parse_timestamp": "2024-01-01T00:00:00Z",
    "confidence_score": 0.95,
    "language": "ko",
    "file_format": "pdf",
    "page_count": 2
  },
  "personal_info": {
    "name": {
      "value": "",
      "confidence": 0.98,
      "bounding_box": []
    },
    "contact": {
      "phone": "",
      "email": "",
      "linkedin": "",
      "github": "",
      "portfolio": ""
    },
    "location": {
      "city": "",
      "country": ""
    }
  },
  "professional_summary": {
    "text": "",
    "keywords": [],
    "sentiment": 0.0
  },
  "experience": [
    {
      "company": {
        "name": "",
        "industry": "",
        "size": ""
      },
      "position": {
        "title": "",
        "level": "",
        "department": ""
      },
      "period": {
        "start": "YYYY-MM-DD",
        "end": "YYYY-MM-DD",
        "duration_months": 0,
        "is_current": false
      },
      "responsibilities": [],
      "achievements": [],
      "technologies": [],
      "metrics": {
        "quantified_achievements": [],
        "impact_score": 0.0
      }
    }
  ],
  "education": [
    {
      "institution": "",
      "degree": "",
      "field": "",
      "gpa": "",
      "graduation_date": "",
      "relevance_score": 0.0
    }
  ],
  "skills": {
    "technical": {
      "languages": [],
      "frameworks": [],
      "databases": [],
      "tools": [],
      "cloud": []
    },
    "soft_skills": [],
    "certifications": [
      {
        "name": "",
        "issuer": "",
        "date": "",
        "verification_url": ""
      }
    ],
    "languages": [
      {
        "language": "",
        "proficiency": ""
      }
    ]
  },
  "projects": [
    {
      "name": "",
      "description": "",
      "technologies": [],
      "url": "",
      "github_stars": 0,
      "contributions": ""
    }
  ],
  "validation": {
    "missing_sections": [],
    "data_quality_issues": [],
    "formatting_issues": []
  }
}
```

## 3. 면접 질문 카테고리 및 생성 전략

### 3.1 질문 유형별 생성 매트릭스

```mermaid
graph LR
    subgraph "기술 질문 (Technical)"
        T1[알고리즘/자료구조]
        T2[시스템 설계]
        T3[코드 리뷰]
        T4[디버깅 시나리오]
        T5[기술 스택 심화]
    end

    subgraph "행동 질문 (Behavioral)"
        B1[리더십 경험]
        B2[갈등 해결]
        B3[실패 극복]
        B4[협업 사례]
        B5[성과 달성]
    end

    subgraph "상황 질문 (Situational)"
        S1[우선순위 결정]
        S2[위기 대응]
        S3[프로젝트 관리]
        S4[고객 대응]
        S5[기술 선택]
    end

    subgraph "문화/가치관 (Cultural Fit)"
        C1[팀워크 스타일]
        C2[학습 방식]
        C3[피드백 수용]
        C4[성장 목표]
        C5[회사 가치관]
    end
```

### 3.2 경력 수준별 질문 난이도 조정

| 레벨 | 기술 깊이 | 프로젝트 규모 | 리더십 | 비즈니스 이해 | 예시 질문 |
|------|----------|-------------|---------|-------------|----------|
| **Junior (0-3년)** | 기초 개념 | 개인/소규모 | 자기 관리 | 기본 이해 | "Array vs LinkedList 차이점은?" |
| **Mid (3-7년)** | 심화 응용 | 팀 프로젝트 | 멘토링 | 도메인 지식 | "마이크로서비스 설계시 고려사항은?" |
| **Senior (7년+)** | 아키텍처 | 대규모 시스템 | 팀 리딩 | 전략적 사고 | "레거시 시스템 현대화 전략은?" |
| **Staff/Principal** | 혁신/R&D | 조직 전체 | 조직 설계 | 비즈니스 임팩트 | "기술 부채 관리 로드맵은?" |

### 3.3 LLM별 질문 생성 프롬프트

```yaml
technical_questions:
  claude_prompt:
    role: "Senior Technical Interviewer"
    context:
      - resume_data
      - job_description
      - tech_stack
    instructions:
      - Generate deep technical questions
      - Focus on problem-solving approach
      - Include follow-up questions
    output_format:
      - question: "main question"
        follow_ups: ["clarification", "edge case", "optimization"]
        evaluation_criteria: ["concept understanding", "practical application"]
        sample_answer_points: ["key concepts to cover"]

behavioral_questions:
  gpt4_prompt:
    role: "HR Behavioral Interview Specialist"
    framework: "STAR Method"
    focus_areas:
      - Leadership situations
      - Conflict resolution
      - Achievement stories
      - Failure and learning
    output_format:
      - question: "Tell me about a time when..."
        probing_questions: ["What was the outcome?", "What did you learn?"]
        red_flags: ["blame others", "no specific example"]
        green_flags: ["ownership", "growth mindset", "quantified impact"]

situational_questions:
  gemini_prompt:
    role: "Engineering Manager"
    scenarios:
      - Technical debt vs feature delivery
      - Team conflict resolution
      - Resource constraints
      - Stakeholder management
    output_format:
      - scenario: "detailed situation"
        question: "How would you handle..."
        evaluation_dimensions: ["analytical", "communication", "decision-making"]

culture_fit_questions:
  llama_prompt:
    role: "Culture Assessment Specialist"
    company_values: ["innovation", "collaboration", "customer-focus"]
    assessment_areas:
      - Work style preferences
      - Team dynamics
      - Growth mindset
      - Company mission alignment
```

## 4. 지능형 질문 생성 엔진

### 4.1 이력서 기반 맞춤 질문 생성

```mermaid
sequenceDiagram
    participant Resume
    participant Analyzer
    participant QuestionGen
    participant LLM
    participant Validator
    participant Output

    Resume->>Analyzer: 파싱된 이력서 데이터
    Analyzer->>Analyzer: 경력 경로 분석
    Analyzer->>Analyzer: 기술 스택 매핑
    Analyzer->>Analyzer: 프로젝트 복잡도 평가
    Analyzer->>Analyzer: 공백 기간 탐지

    Analyzer->>QuestionGen: 분석 결과
    QuestionGen->>QuestionGen: 질문 템플릿 선택
    QuestionGen->>QuestionGen: 난이도 결정
    QuestionGen->>QuestionGen: 우선순위 설정

    QuestionGen->>LLM: 질문 생성 요청
    LLM->>LLM: 컨텍스트 기반 생성
    LLM->>Validator: 생성된 질문

    Validator->>Validator: 중복 제거
    Validator->>Validator: 적절성 검증
    Validator->>Validator: 난이도 균형 조정

    Validator->>Output: 최종 질문 세트
```

### 4.2 질문 깊이 조절 알고리즘

```json
{
  "question_depth_matrix": {
    "surface_level": {
      "purpose": "기본 지식 확인",
      "examples": [
        "REST API란 무엇인가요?",
        "Git의 주요 명령어를 설명해주세요"
      ],
      "time_allocation": "2-3분"
    },
    "application_level": {
      "purpose": "실무 적용 능력",
      "examples": [
        "대용량 트래픽 처리 경험을 설명해주세요",
        "CI/CD 파이프라인을 구축한 경험은?"
      ],
      "time_allocation": "5-7분"
    },
    "problem_solving": {
      "purpose": "문제 해결 능력",
      "examples": [
        "프로덕션 장애 대응 경험을 공유해주세요",
        "기술 부채를 해결한 사례는?"
      ],
      "time_allocation": "10-15분"
    },
    "architecture_design": {
      "purpose": "설계 및 추상화 능력",
      "examples": [
        "결제 시스템을 설계한다면?",
        "MSA 전환 전략을 수립한다면?"
      ],
      "time_allocation": "20-30분"
    }
  }
}
```

### 4.3 프로젝트 기반 심화 질문

```yaml
project_analysis:
  extraction_points:
    - technology_used
    - team_size
    - project_duration
    - business_impact
    - technical_challenges

  question_generation:
    technical_deep_dive:
      - "이 프로젝트에서 {technology}를 선택한 이유는?"
      - "{challenge}를 어떻게 해결했나요?"
      - "성능 최적화는 어떻게 진행했나요?"

    collaboration:
      - "{team_size}명 팀에서 어떻게 협업했나요?"
      - "의견 충돌은 어떻게 조율했나요?"
      - "코드 리뷰 프로세스는?"

    business_impact:
      - "비즈니스 지표 개선 효과는?"
      - "사용자 피드백은 어땠나요?"
      - "런칭 후 모니터링 전략은?"

  follow_up_patterns:
    - "더 자세히 설명해주실 수 있나요?"
    - "다시 한다면 무엇을 개선하시겠어요?"
    - "가장 큰 교훈은 무엇이었나요?"
```

## 5. n8n 워크플로우 구현

### 5.1 워크플로우 JSON 템플릿

```json
{
  "name": "Interview Question Generator",
  "nodes": [
    {
      "id": "webhook",
      "type": "n8n-nodes-base.webhook",
      "parameters": {
        "path": "interview-questions",
        "responseMode": "lastNode",
        "httpMethod": "POST"
      }
    },
    {
      "id": "dolphin_api",
      "type": "n8n-nodes-base.httpRequest",
      "parameters": {
        "url": "http://localhost:8000/parse",
        "method": "POST",
        "bodyParameters": {
          "file": "={{$json.resume}}",
          "mode": "page_level"
        }
      }
    },
    {
      "id": "parallel_llm",
      "type": "n8n-nodes-base.split",
      "parameters": {
        "batchSize": 1,
        "options": {
          "batches": [
            {"llm": "claude", "type": "technical"},
            {"llm": "gpt4", "type": "behavioral"},
            {"llm": "gemini", "type": "situational"}
          ]
        }
      }
    },
    {
      "id": "merge_results",
      "type": "n8n-nodes-base.merge",
      "parameters": {
        "mode": "multiplex"
      }
    },
    {
      "id": "format_output",
      "type": "n8n-nodes-base.function",
      "parameters": {
        "functionCode": "return formatInterviewQuestions($input.all())"
      }
    }
  ]
}
```

### 5.2 외부 데이터 소스 통합

```mermaid
graph LR
    subgraph "실시간 데이터 수집"
        A[LinkedIn API] --> D[데이터 통합]
        B[GitHub API] --> D
        C[Stack Overflow] --> D
        E[Glassdoor] --> D
    end

    D --> F{검증 및 보강}
    F --> G[질문 맥락화]
    G --> H[최종 질문 세트]
```

### 5.3 캐싱 및 성능 최적화

```yaml
caching_strategy:
  redis:
    resume_parse_cache:
      ttl: 3600  # 1시간
      key_pattern: "resume:{hash}"

    question_cache:
      ttl: 86400  # 24시간
      key_pattern: "questions:{job_id}:{level}"

    llm_response_cache:
      ttl: 7200  # 2시간
      key_pattern: "llm:{model}:{prompt_hash}"

  performance_optimization:
    - Parallel LLM calls
    - Batch processing for multiple resumes
    - Async I/O operations
    - Connection pooling for APIs
```

## 6. 면접 질문 출력 형식

### 6.1 구조화된 질문 세트 (JSON)

```json
{
  "interview_set": {
    "candidate_name": "김개발",
    "position": "Senior Backend Engineer",
    "total_questions": 25,
    "estimated_duration": "90분",
    "difficulty_distribution": {
      "easy": 5,
      "medium": 12,
      "hard": 8
    },
    "categories": {
      "technical": {
        "count": 10,
        "questions": [
          {
            "id": "T001",
            "question": "마이크로서비스 간 트랜잭션 관리 방법은?",
            "difficulty": "hard",
            "expected_time": "10분",
            "evaluation_criteria": [
              "Saga 패턴 이해",
              "2PC vs Eventual Consistency",
              "실제 구현 경험"
            ],
            "follow_ups": [
              "보상 트랜잭션 구현 방법은?",
              "실패 시나리오 처리는?"
            ],
            "good_answer_includes": [
              "Choreography vs Orchestration",
              "Outbox 패턴",
              "Idempotency"
            ]
          }
        ]
      },
      "behavioral": {
        "count": 8,
        "questions": [
          {
            "id": "B001",
            "question": "기술적 의견 충돌을 해결한 경험은?",
            "difficulty": "medium",
            "expected_time": "7분",
            "star_components": {
              "situation": "팀 내 기술 선택 갈등",
              "task": "합의 도출",
              "action": "데이터 기반 의사결정",
              "result": "성공적 구현"
            }
          }
        ]
      }
    }
  }
}
```

### 6.2 면접관용 가이드

```markdown
# 면접 진행 가이드

## 시간 배분
- Ice Breaking: 5분
- 기술 질문: 40분
- 행동 질문: 30분
- 상황 질문: 10분
- 질의응답: 5분

## 평가 체크리스트
□ 기술 깊이
□ 문제 해결 접근법
□ 커뮤니케이션 스킬
□ 팀워크 능력
□ 학습 의지

## Red Flags
- 구체적 사례 없음
- 책임 회피
- 과도한 과장
- 기술 트렌드만 언급

## Green Flags
- 구체적 숫자/지표
- 실패 경험 공유
- 개선 의지
- 팀 기여도 언급
```

### 6.3 지원자용 준비 가이드

```yaml
preparation_guide:
  technical_preparation:
    - Review your projects in detail
    - Prepare system design examples
    - Practice coding problems
    - Research company tech stack

  behavioral_preparation:
    - Prepare 5-7 STAR stories
    - Quantify your achievements
    - Think about failures and learnings
    - Research company culture

  questions_to_ask:
    - Team structure and collaboration
    - Technical challenges
    - Growth opportunities
    - Work-life balance
```

## 7. 구현 로드맵

### Phase 1: MVP (2주)
- [ ] Dolphin API 서버 구축
- [ ] 기본 파싱 로직 구현
- [ ] 단일 LLM 통합 (Claude)
- [ ] CLI 인터페이스

### Phase 2: 고도화 (3주)
- [ ] 다중 LLM 통합
- [ ] n8n 워크플로우 구성
- [ ] 질문 DB 구축
- [ ] 난이도 조절 알고리즘

### Phase 3: 확장 (4주)
- [ ] 외부 API 연동
- [ ] 웹 인터페이스
- [ ] 면접 시뮬레이터
- [ ] 분석 대시보드

### Phase 4: 운영 (지속)
- [ ] A/B 테스트
- [ ] 질문 품질 개선
- [ ] 사용자 피드백 반영
- [ ] 성능 최적화

## 8. 확장 가능성

### 8.1 AI 면접관 시뮬레이터
- 실시간 음성 인식
- 답변 분석 및 피드백
- 모의 면접 녹화
- 개선점 레포트

### 8.2 기업 맞춤형 서비스
- 회사별 면접 스타일 학습
- 과거 합격자 패턴 분석
- 직무 기술서 자동 매칭
- 맞춤형 준비 커리큘럼

### 8.3 데이터 기반 인사이트
- 업계별 면접 트렌드
- 인기 질문 통계
- 합격률 예측 모델
- 경력 개발 로드맵

## 9. 재귀적(Recursive) 면접 워크플로우

### 9.0 아키텍처 비교: n8n vs LangGraph

| 특징 | n8n | LangGraph |
|------|-----|-----------|
| **API 호출** | 복잡한 Webhook 설정 | 간단한 REST/GraphQL API |
| **상태 관리** | 외부 DB 필요 | 내장 상태 관리 |
| **복잡한 로직** | GUI 제약 | Python 코드로 자유도 높음 |
| **LLM 통합** | 별도 연결 필요 | 네이티브 지원 |
| **에러 처리** | 제한적 | 풍부한 예외 처리 |
| **확장성** | 수평 확장 어려움 | Kubernetes 배포 용이 |
| **디버깅** | UI 로그만 | 상세한 Python 디버깅 |

**결론**: 외부 API 호출이 주목적이라면 **LangGraph 권장**

### 9.1 적응형 질문 생성 시스템

```mermaid
graph TD
    Start([초기 질문 세트]) --> Ask[질문 제시]
    Ask --> Response[답변 수집]
    Response --> Analyze{답변 분석}

    Analyze -->|깊이 부족| Deeper[심화 질문 생성]
    Analyze -->|이해도 높음| Harder[난이도 상승]
    Analyze -->|이해도 낮음| Easier[난이도 하향]
    Analyze -->|새로운 토픽 발견| Branch[분기 질문]

    Deeper --> Ask
    Harder --> Ask
    Easier --> Ask
    Branch --> Ask

    Analyze -->|충분한 평가| End[평가 완료]
```

### 9.2 LangGraph 상태 머신 설계

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class InterviewState(TypedDict):
    resume_data: dict
    current_question: str
    answer_history: List[dict]
    candidate_profile: dict
    difficulty_level: float
    coverage_map: dict
    session_id: str
    interview_phase: str

def create_interview_graph():
    workflow = StateGraph(InterviewState)

    # 노드 정의
    workflow.add_node("parse_resume", parse_resume_node)
    workflow.add_node("generate_initial_questions", initial_questions_node)
    workflow.add_node("analyze_response", analyze_response_node)
    workflow.add_node("decide_next_action", decision_engine_node)
    workflow.add_node("generate_followup", followup_question_node)
    workflow.add_node("generate_branch", branch_question_node)
    workflow.add_node("adjust_difficulty", difficulty_adjustment_node)
    workflow.add_node("finalize_assessment", assessment_node)

    # 엣지 정의
    workflow.set_entry_point("parse_resume")
    workflow.add_edge("parse_resume", "generate_initial_questions")
    workflow.add_edge("generate_initial_questions", "decide_next_action")
    workflow.add_edge("analyze_response", "decide_next_action")

    # 조건부 엣지
    workflow.add_conditional_edges(
        "decide_next_action",
        route_decision,
        {
            "followup": "generate_followup",
            "branch": "generate_branch",
            "adjust": "adjust_difficulty",
            "end": "finalize_assessment"
        }
    )

    workflow.add_edge("generate_followup", "analyze_response")
    workflow.add_edge("generate_branch", "analyze_response")
    workflow.add_edge("adjust_difficulty", "analyze_response")
    workflow.add_edge("finalize_assessment", END)

    return workflow.compile()

# 라우팅 로직
def route_decision(state: InterviewState) -> str:
    last_answer = state["answer_history"][-1]
    confidence = last_answer.get("confidence", 0.5)
    depth = last_answer.get("depth_score", 0.5)

    if len(state["answer_history"]) > 10:
        return "end"
    elif confidence < 0.6:
        return "followup"
    elif depth > 0.8 and "new_topic" in last_answer:
        return "branch"
    else:
        return "adjust"
```

### 9.3 피드백 루프 시스템

```mermaid
sequenceDiagram
    participant Candidate
    participant System
    participant LLM
    participant Evaluator

    loop Recursive Interview
        System->>Candidate: Present Question
        Candidate->>System: Provide Answer
        System->>LLM: Analyze Response
        LLM->>LLM: Extract Insights
        LLM->>System: Generate Follow-up
        System->>Evaluator: Update Score
        Evaluator->>System: Adjust Strategy
    end

    System->>Candidate: Final Feedback
```

### 9.4 동적 난이도 조정 알고리즘

```json
{
  "difficulty_adjustment": {
    "metrics": {
      "response_time": {
        "fast": "< 30s",
        "normal": "30s - 2min",
        "slow": "> 2min"
      },
      "answer_quality": {
        "excellent": 0.9,
        "good": 0.7,
        "fair": 0.5,
        "poor": 0.3
      }
    },
    "rules": [
      {
        "condition": "answer_quality > 0.8 AND response_time == 'fast'",
        "action": "increase_difficulty",
        "delta": 0.2
      },
      {
        "condition": "answer_quality < 0.5",
        "action": "decrease_difficulty",
        "delta": -0.15
      },
      {
        "condition": "consecutive_poor_answers >= 2",
        "action": "switch_topic",
        "reason": "candidate struggling with current area"
      }
    ],
    "branching_triggers": [
      "Interesting project mentioned",
      "Unique technology experience",
      "Problem-solving approach",
      "Leadership example"
    ]
  }
}
```

### 9.5 FastAPI + LangGraph 통합

```python
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel
import asyncio

app = FastAPI(title="Interview Question Generator API")

class InterviewRequest(BaseModel):
    resume_file: str
    job_description: str
    position_level: str
    session_id: str

class InterviewResponse(BaseModel):
    question: str
    context: dict
    expected_duration: int
    evaluation_criteria: list

@app.post("/interview/start")
async def start_interview(request: InterviewRequest):
    """이력서 기반 면접 세션 시작"""

    # LangGraph 워크플로우 초기화
    workflow = create_interview_graph()

    initial_state = {
        "resume_data": await parse_resume(request.resume_file),
        "job_description": request.job_description,
        "session_id": request.session_id,
        "difficulty_level": get_initial_difficulty(request.position_level),
        "answer_history": [],
        "coverage_map": initialize_coverage_map()
    }

    # 첫 질문 생성
    result = await workflow.ainvoke(initial_state)

    return InterviewResponse(
        question=result["current_question"],
        context=result["question_context"],
        expected_duration=result["estimated_time"],
        evaluation_criteria=result["evaluation_points"]
    )

@app.post("/interview/{session_id}/answer")
async def process_answer(
    session_id: str,
    answer: str,
    background_tasks: BackgroundTasks
):
    """답변 처리 및 다음 질문 생성"""

    # 세션 상태 로드
    current_state = await load_session_state(session_id)

    # 답변 분석 및 다음 질문 생성
    updated_state = current_state.copy()
    updated_state["current_answer"] = answer

    workflow = create_interview_graph()
    result = await workflow.ainvoke(updated_state)

    # 세션 상태 저장 (백그라운드)
    background_tasks.add_task(save_session_state, session_id, result)

    if result.get("interview_complete"):
        return {"status": "completed", "final_assessment": result["assessment"]}

    return InterviewResponse(
        question=result["current_question"],
        context=result["question_context"],
        expected_duration=result["estimated_time"],
        evaluation_criteria=result["evaluation_points"]
    )

@app.get("/interview/{session_id}/status")
async def get_interview_status(session_id: str):
    """면접 진행 상태 조회"""

    state = await load_session_state(session_id)

    return {
        "questions_asked": len(state["answer_history"]),
        "coverage_percentage": calculate_coverage(state["coverage_map"]),
        "current_difficulty": state["difficulty_level"],
        "estimated_remaining_time": estimate_remaining_time(state)
    }
```

### 9.6 완전한 LangGraph 워크플로우 다이어그램

```mermaid
graph TB
    Start([API 호출<br/>POST /interview/start]) --> Validate{입력 검증}
    Validate -->|Valid| ParseResume[parse_resume<br/>Dolphin API 호출]
    Validate -->|Invalid| ErrorReturn[400 Error Return]

    ParseResume --> ExtractProfile[extract_profile<br/>후보자 프로필 생성]
    ExtractProfile --> InitSession[initialize_session<br/>세션 상태 초기화]

    InitSession --> GenInitQ[generate_initial_questions<br/>초기 질문 세트 생성]
    GenInitQ --> StoreSession[(Redis<br/>세션 저장)]
    StoreSession --> ReturnQ1[첫 번째 질문 반환]

    %% 재귀 루프 시작
    ReturnQ1 --> WaitAnswer[답변 대기<br/>POST /answer]
    WaitAnswer --> LoadSession[(Redis<br/>세션 로드)]

    LoadSession --> AnalyzeAnswer[analyze_response<br/>답변 분석 & 점수화]
    AnalyzeAnswer --> UpdateHistory[update_answer_history<br/>답변 이력 업데이트]

    UpdateHistory --> DecisionEngine{decide_next_action<br/>다음 액션 결정}

    %% 조건부 라우팅
    DecisionEngine -->|답변 부족| GenFollowup[generate_followup<br/>심화 질문 생성]
    DecisionEngine -->|새 토픽 발견| GenBranch[generate_branch<br/>분기 질문 생성]
    DecisionEngine -->|난이도 조정| AdjustDiff[adjust_difficulty<br/>난이도 재조정]
    DecisionEngine -->|충분히 평가됨| CheckCoverage{coverage_check<br/>커버리지 확인}
    DecisionEngine -->|시간/횟수 초과| ForceEnd[force_finalize<br/>강제 종료]

    %% 질문 생성 노드들
    GenFollowup --> LLMFollowup[Claude API<br/>컨텍스트 기반<br/>심화 질문]
    GenBranch --> LLMBranch[GPT-4 API<br/>새 영역<br/>탐색 질문]
    AdjustDiff --> LLMAdjust[Gemini API<br/>난이도 조정된<br/>질문]

    %% LLM 결과 처리
    LLMFollowup --> ValidateQ[validate_question<br/>질문 품질 검증]
    LLMBranch --> ValidateQ
    LLMAdjust --> ValidateQ

    ValidateQ --> UpdateSession[(Redis<br/>세션 업데이트)]
    UpdateSession --> ReturnNext[다음 질문 반환]
    ReturnNext --> WaitAnswer

    %% 종료 조건들
    CheckCoverage -->|Coverage < 80%| GenSupplementary[generate_supplementary<br/>보완 질문 생성]
    CheckCoverage -->|Coverage >= 80%| FinalizeAssessment[finalize_assessment<br/>최종 평가 생성]
    GenSupplementary --> LLMSupplement[LLM API<br/>보완 질문]
    LLMSupplement --> ValidateQ

    ForceEnd --> FinalizeAssessment
    FinalizeAssessment --> GenerateReport[generate_report<br/>면접 리포트 작성]
    GenerateReport --> StoreResults[(PostgreSQL<br/>결과 저장)]
    StoreResults --> CleanupSession[cleanup_session<br/>Redis 정리]
    CleanupSession --> EndReturn[면접 완료 응답]

    %% 상태 조회 엔드포인트
    StatusAPI[GET /status] --> LoadStatusSession[(Redis 로드)]
    LoadStatusSession --> CalcStatus[calculate_metrics<br/>진행률 계산]
    CalcStatus --> StatusReturn[상태 정보 반환]

    %% 에러 처리
    LLMFollowup -.->|API 오류| RetryLogic[retry_with_backoff<br/>재시도 로직]
    LLMBranch -.->|API 오류| RetryLogic
    LLMAdjust -.->|API 오류| RetryLogic
    RetryLogic -.->|재시도 성공| ValidateQ
    RetryLogic -.->|최종 실패| FallbackQuestion[fallback_question<br/>기본 질문 사용]
    FallbackQuestion --> ValidateQ

    %% 스타일링
    classDef startEnd fill:#e1f5fe
    classDef process fill:#f3e5f5
    classDef decision fill:#fff3e0
    classDef llm fill:#e8f5e8
    classDef storage fill:#fce4ec
    classDef error fill:#ffebee

    class Start,ReturnQ1,ReturnNext,EndReturn,StatusReturn startEnd
    class ParseResume,ExtractProfile,AnalyzeAnswer,UpdateHistory,GenerateReport process
    class Validate,DecisionEngine,CheckCoverage decision
    class LLMFollowup,LLMBranch,LLMAdjust,LLMSupplement llm
    class StoreSession,LoadSession,UpdateSession,StoreResults,LoadStatusSession storage
    class ErrorReturn,RetryLogic,FallbackQuestion error
```

### 9.7 노드별 상세 기능

```python
# 주요 노드 구현 예시
async def parse_resume_node(state: InterviewState) -> InterviewState:
    """Dolphin을 이용한 이력서 파싱"""
    resume_data = await dolphin_api.parse_document(
        file_path=state["resume_file"],
        mode="comprehensive"
    )

    return {
        **state,
        "resume_data": resume_data,
        "parsing_confidence": resume_data["metadata"]["confidence_score"]
    }

async def analyze_response_node(state: InterviewState) -> InterviewState:
    """답변 분석 및 점수화"""
    current_answer = state["current_answer"]

    # 다중 LLM 평가
    claude_analysis = await claude_api.analyze_response(
        question=state["current_question"],
        answer=current_answer,
        context=state["candidate_profile"]
    )

    # 점수 통합
    combined_score = integrate_scores([claude_analysis])

    # 답변 이력에 추가
    answer_entry = {
        "question": state["current_question"],
        "answer": current_answer,
        "timestamp": datetime.now(),
        "analysis": combined_score,
        "confidence": claude_analysis["confidence"],
        "depth_score": claude_analysis["depth"],
        "new_topics": claude_analysis.get("discovered_topics", [])
    }

    return {
        **state,
        "answer_history": state["answer_history"] + [answer_entry],
        "current_score": update_running_score(state.get("current_score", {}), combined_score)
    }

async def decide_next_action_node(state: InterviewState) -> InterviewState:
    """다음 행동 결정"""
    last_answer = state["answer_history"][-1]

    # 종료 조건 체크
    if len(state["answer_history"]) >= MAX_QUESTIONS:
        return {**state, "next_action": "end"}

    if state.get("interview_duration", 0) >= MAX_DURATION:
        return {**state, "next_action": "end"}

    # 답변 품질 기반 결정
    confidence = last_answer["confidence"]
    depth = last_answer["depth_score"]

    if confidence < 0.6:
        return {**state, "next_action": "followup"}
    elif depth > 0.8 and last_answer["new_topics"]:
        return {**state, "next_action": "branch"}
    elif should_adjust_difficulty(state):
        return {**state, "next_action": "adjust"}
    else:
        return {**state, "next_action": "continue"}

async def generate_followup_node(state: InterviewState) -> InterviewState:
    """심화 질문 생성"""
    last_qa = state["answer_history"][-1]

    followup_prompt = f"""
    이전 질문: {last_qa['question']}
    답변: {last_qa['answer']}
    분석: 답변이 표면적이고 구체적인 예시가 부족함

    더 깊이 있는 답변을 이끌어낼 심화 질문을 생성하세요.
    """

    followup_question = await claude_api.generate_question(
        prompt=followup_prompt,
        context=state["candidate_profile"],
        difficulty_level=state["difficulty_level"]
    )

    return {
        **state,
        "current_question": followup_question["question"],
        "question_context": followup_question["context"],
        "question_type": "followup"
    }
```

## 참고 자료
- Dolphin 논문: https://arxiv.org/abs/2406.18842
- HuggingFace 모델: https://huggingface.co/ByteDance/Dolphin
- n8n 문서: https://docs.n8n.io
- STAR Method: https://www.thebalancecareers.com/star-interview-method